# Diffusion Models in NLP: Evolution, Applications, and Future Perspectives

## Content

- Description
- Chronological Order
- 

## Chronological Order

### 2023

### 2022

**1. Diffusion-LM Improves Controllable Text Generation.** [27 May 2022]

*Xiang Li, John Thickstun, Ishaan Gulrajani, Percy S. Liang, Tatsunori B. Hashimoto*

[[links](https://proceedings.neurips.cc/paper_files/paper/2022/hash/1be5bc25d50895ee656b8c2d9eb89d6a-Abstract-Conference.html)][NeurIPS 2022]



**2. Latent Diffusion Energy-Based Model for Interpretable Text Modeling.** [13 June 2022 (v1)] [4 Jul 2022 (v3)] [4 Oct 2023 (v4)]

*Peiyu Yu, Sirui Xie, Xiaojian Ma, Baoxiong Jia, Bo Pang, Ruiqi Gao, Yixin Zhu, Song-Chun Zhu, Ying Nian Wu*

[[links](https://arxiv.org/abs/2206.05895)][ICML 2022]



**3. DiffusER: Discrete Diffusion via Edit-based Reconstruction.**  [30 Oct 2022]

*Machel Reid, Vincent J. Hellendoorn, Graham Neubig*

[[links](https://arxiv.org/abs/2210.16886)]



**4. SELF-CONDITIONED EMBEDDING DIFFUSION FOR TEXT GENERATION.**  [8 Nov 2022]

*Robin Strudel, Corentin Tallec, Florent Altche, Yilun Du, Yaroslav Ganin, Arthur Mensch, Will Grathwohl, Nikolay Savinov, Sander Dieleman, Laurent Sifre, Remi Leblond*

[[links](https://arxiv.org/abs/2211.04236)]



**5. DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models.**  [28 Nov 2022]

*Zhengfu He, Tianxiang Sun, Kuanning Wang, Xuanjing Huang, Xipeng Qiu*

[[links](https://arxiv.org/abs/2211.15029)]



**6. Continuous diffusion for categorical data.** [28 Nov 2022 (v1)] [15 Dec 2022 (v3)]

*Sander Dieleman, Laurent Sartran, Arman Roshannai, Nikolay Savinov, Yaroslav Ganin, Pierre H. Richemond, Arnaud Doucet, Robin Strudel, Chris Dyer, Conor Durkan, Curtis Hawthorne, Rémi Leblond, Will Grathwohl and Jonas Adler*

[[links](https://arxiv.org/abs/2211.15089)]



**7. Latent Diffusion for Language Generation.** [19 Dec 2022 (v1)][7 Nov 2023 (v2)]

*Justin Lovelace, Varsha Kishore, Chao Wan, Eliot Shekhtman, Kilian Weinberger*

[[links]([[2212.09462] Latent Diffusion for Language Generation](https://arxiv.org/abs/2212.09462))]





### 2021

**1. Structured Denoising Diffusion Models in Discrete State-Spaces.**  [10 Nov 2021]
*Jacob Austin, Daniel D. Johnson, Jonathan Ho, Daniel Tarlow, Rianne van den Berg*

[[links](https://proceedings.neurips.cc/paper/2021/hash/958c530554f78bcd8e97125b70e6973d-Abstract.html)] [NeurIPS 2021]



**2. Beyond In-Place Corruption: Insertion and Deletion In Denoising Probabilistic Models.**  [16 Jul 2021]

*Daniel D. Johnson, Jacob Austin, Rianne van den Berg, Daniel Tarlow*

[[links](https://arxiv.org/abs/2107.07675)] 



**3. Zero-Shot Translation using Diffusion Models.**  [2 Nov 2021]

*Eliya Nachmani, Shaked Dovrat*

[[links](https://arxiv.org/abs/2111.01471)]



**4. Argmax Flows and Multinomial Diffusion: Learning Categorical Distributions.** [10 Nov 2021]

*Emiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick Forré, Max Welling*

[[links](https://openreview.net/forum?id=6nbpPqUCIi7)][NeurIPS 2021]



**5. Autoregressive Diffusion Models.** [5 Oct 2021 (v1)] [1 Feb 2022 (v2)]

*Emiel Hoogeboom, Alexey A. Gritsenko, Jasmijn Bastings, Ben Poole,  Rianne van den Berg, Tim Salimans*

[[links](https://openreview.net/pdf?id=Lm8T39vLDTE)][ICLR 2022]



**6.Step-unrolled Denoising Autoencoders for Text Generation.** [13 Dec 2021 (v1)][24 Feb 2022 (v2)] [19 Apr 2022 (v3)]

*Nikolay Savinov, Junyoung Chung, Mikołaj Bin ́kowski, Erich Elsen, Aaron van den Oord*

[[links](https://arxiv.org/pdf/2112.06749.pdf)][ICLR 2022]




